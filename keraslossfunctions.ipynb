{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keraslossfunctions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGUYcQ5xt0gZzn/oaCkAVM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QtSP4-Hq58sB",
        "outputId": "09b3de90-66a9-41c0-c4ca-9d892eca6ee9"
      },
      "source": [
        "\"\"\"\n",
        "When designing models we compile it with losses and other metrics\n",
        "with keras it is possible to design loss functions that take in more than just y_pred and y_true\n",
        "\"\"\"\n",
        "from keras import layers, models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nWhen designing models we compile it with losses and other metrics\\nwith keras it is possible to design loss functions that take in more than just y_pred and y_true\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWnaTaa_7ssu"
      },
      "source": [
        "\"\"\"\n",
        "Constructing a custom metric\n",
        "\"\"\"\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def mean_pred(y_true, y_pred):\n",
        "  return K.mean(y_pred)\n",
        "\n",
        "model.compile(optimzer='adam', loss='binary_cross_entropy', metrics=['accuracy', mean_pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67GeeNIr9rH0"
      },
      "source": [
        "\"\"\"\n",
        "Loss function with multiple arguments\n",
        "Building a loss function that adds the mean square value for all activations in the fisrst layer to the MSE\n",
        "\"\"\"\n",
        "# Build a model\n",
        "inputs = Input(shape=(128,))\n",
        "layer1 = Dense(64, activation='relu')(inputs)\n",
        "layer2 = Dense(64, activation='relu')(layer1)\n",
        "predictions = Dense(10, activation='softmax')(layer2)\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "def custome_classification(layer):\n",
        "  def loss(y_pred, y_true):\n",
        "    return K.mean(K.square(y_pred, y_true) + K.square(layer), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}